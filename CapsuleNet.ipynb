{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = '/home/wilsonyan/data/mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dset_train = datasets.MNIST(root, train=True, download=True, transform=transform)\n",
    "dset_test = datasets.MNIST(root, train=False, download=True, transform=transform)\n",
    "\n",
    "loader_train = data.DataLoader(dset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = data.DataLoader(dset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(x, dim=-1):\n",
    "    norm_squared = torch.sum(x ** 2, dim, keepdim=True)\n",
    "    x = norm_squared / (1 + norm_squared) * x / torch.sqrt(norm_squared)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def margin_loss(out, y):\n",
    "    pred = torch.sqrt((out ** 2).sum(-1))\n",
    "    loss = y * torch.max(0.9 - pred, 0)[0] ** 2 + 0.5 * (1 - y) * torch.max(pred - 0.1, 0)[0] ** 2\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse_loss(out, y):\n",
    "    return torch.sum((out - y) ** 2) / out.data.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, n_dim):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.conv = nn.Conv2d(256, 32 * 8, 9, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1, self.n_dim)\n",
    "        x = squash(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, n_dim, prev_dim, n_iter):\n",
    "        super(DigitCaps, self).__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.prev_dim = prev_dim\n",
    "        self.n_iter = n_iter\n",
    "        self.weights = nn.Parameter(torch.randn(10, 6 * 6 * 32, prev_dim, n_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1).unsqueeze(3)\n",
    "        u_hat = torch.matmul(x, self.weights).squeeze(3)\n",
    "        \n",
    "        b = Variable(torch.zeros(10, 6 * 6 * 32))\n",
    "        for i in range(self.n_iter):\n",
    "            c = F.softmax(b)\n",
    "            s = u_hat.mul(c.unsqueeze(0).unsqueeze(3)).sum(2)\n",
    "            v = squash(s)\n",
    "            if i < self.n_iter - 1:\n",
    "                b = b + u_hat.mul(v.unsqueeze(2)).sum(-1).sum(0)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsuleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsuleNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 256, 9)\n",
    "        self.primary_caps = PrimaryCaps(8)\n",
    "        self.digit_caps = DigitCaps(16, 8, 5)\n",
    "        self.fc1 = nn.Linear(160, 512)\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 784)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.primary_caps(x)\n",
    "        out = self.digit_caps(x)\n",
    "        x = out.view(out.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        reconstruction = x.view(x.size()[0], 28, 28)\n",
    "        return out, reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CapsuleNet()\n",
    "optimizer = optim.RMSprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader, num_epochs=10, show_every=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch %s' % epoch)\n",
    "        print('=' * 10)\n",
    "        losses = []\n",
    "        for i, (x, y) in enumerate(iter(loader)):\n",
    "            y_one_hot = torch.FloatTensor(y.size()[0], 10)\n",
    "            y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n",
    "            x, y_one_hot = Variable(x), Variable(y_one_hot)\n",
    "            out, reconstruction = model(x)\n",
    "            loss_margin = margin_loss(out, y_one_hot)\n",
    "            loss_rec = mse_loss(x, reconstruction)\n",
    "            loss = loss_margin + 0.0005 * loss_rec\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.data[0])\n",
    "            if i * show_every == 0:\n",
    "                print('Loss: %s' % np.mean(losses))\n",
    "            \n",
    "        print('Mean Loss: %s' % np.mean(losses))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "==========\n",
      "Loss: -2.11439733168e+32\n"
     ]
    }
   ],
   "source": [
    "model = train(model, optimizer, loader_train, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
