{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = '/home/wilsonyan/data/mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dset_train = datasets.MNIST(root, train=True, download=True, transform=transform)\n",
    "dset_test = datasets.MNIST(root, train=False, download=True, transform=transform)\n",
    "\n",
    "loader_train = data.DataLoader(dset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = data.DataLoader(dset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(x, dim=-1):\n",
    "    norm_squared = torch.sum(x ** 2, dim, keepdim=True)\n",
    "    x = norm_squared / (1 + norm_squared) * x / torch.sqrt(norm_squared)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def margin_loss(out, y):\n",
    "    pred = torch.sqrt((out ** 2).sum(-1))\n",
    "    loss = y * torch.max(0.9 - pred, 0)[0] ** 2 + 0.5 * (1 - y) * torch.max(pred - 0.1, 0)[0] ** 2\n",
    "    return loss.sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse_loss(out, y):\n",
    "    return torch.sum((out - y) ** 2) / out.data.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(input, dim=1):\n",
    "    input_size = input.size()\n",
    "    \n",
    "    trans_input = input.transpose(dim, len(input_size)-1)\n",
    "    trans_size = trans_input.size()\n",
    "\n",
    "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
    "    \n",
    "    soft_max_2d = F.softmax(input_2d)\n",
    "    \n",
    "    soft_max_nd = soft_max_2d.view(*trans_size)\n",
    "    return soft_max_nd.transpose(dim, len(input_size)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, n_dim):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.conv = nn.Conv2d(256, 32 * 8, 9, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1, self.n_dim)\n",
    "        x = squash(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, n_dim, prev_dim, n_iter):\n",
    "        super(DigitCaps, self).__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.prev_dim = prev_dim\n",
    "        self.n_iter = n_iter\n",
    "        self.weights = nn.Parameter(torch.randn(10, 6 * 6 * 32, prev_dim, n_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0).unsqueeze(3)\n",
    "        u_hat = torch.matmul(x, self.weights.unsqueeze(1))\n",
    "        \n",
    "        b = Variable(torch.zeros(*u_hat.size()))\n",
    "        for i in range(self.n_iter):\n",
    "            \n",
    "            c = softmax(b, dim=2)\n",
    "            s = (u_hat * c).sum(2, keepdim=True)\n",
    "            v = squash(s)\n",
    "            \n",
    "            if i < self.n_iter - 1:\n",
    "                b = b + (u_hat * v).sum(-1, keepdim=True)\n",
    "        v = v.squeeze(2).squeeze(2).permute(1, 0, 2).contiguous()\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsuleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsuleNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 256, 9)\n",
    "        self.primary_caps = PrimaryCaps(8)\n",
    "        self.digit_caps = DigitCaps(16, 8, 3)\n",
    "        self.fc1 = nn.Linear(160, 512)\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 784)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.primary_caps(x)\n",
    "        out = self.digit_caps(x)\n",
    "        x = out.view(out.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        reconstruction = x.view(x.size()[0], 28, 28)\n",
    "        return out, reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader, num_epochs=10, show_every=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch %s' % epoch)\n",
    "        print('=' * 10)\n",
    "        losses = []\n",
    "        for i, (x, y) in enumerate(iter(loader)):\n",
    "#             y_one_hot = torch.FloatTensor(y.size()[0], 10)\n",
    "#             y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n",
    "#             x, y_one_hot = Variable(x), Variable(y_one_hot)\n",
    "            x, y = Variable(x), Variable(y)\n",
    "            out, reconstruction = model(x)\n",
    "#             loss_margin = margin_loss(out, y_one_hot)\n",
    "            logits = torch.sqrt((out ** 2).sum(-1))\n",
    "            loss_margin = criterion(logits, y)\n",
    "            loss_rec = 0.05 * mse_loss(x, reconstruction)\n",
    "            loss = loss_margin + loss_rec\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(i, loss_margin.data[0], loss_rec.data[0], loss.data[0])\n",
    "            losses.append(loss.data[0])\n",
    "            if i % show_every == 0:\n",
    "                print('Loss: %s' % np.mean(losses))\n",
    "            \n",
    "        print('Mean Loss: %s' % np.mean(losses))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CapsuleNet()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 8141840\n"
     ]
    }
   ],
   "source": [
    "print('Parameters: %s' % sum(param.numel() for param in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "==========\n",
      "torch.Size([32, 10, 16])\n",
      "torch.Size([32, 10, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 160], m2: [16 x 512] at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:1293",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-da92db0c3b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-3023eb94c867>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader, num_epochs, show_every)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#             x, y_one_hot = Variable(x), Variable(y_one_hot)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#             loss_margin = margin_loss(out, y_one_hot)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-006bfe59d670>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 160], m2: [16 x 512] at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:1293"
     ]
    }
   ],
   "source": [
    "model = train(model, optimizer, loader_train, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, dset):    \n",
    "    x, y = random.choice(dset)\n",
    "    x = Variable(x.unsqueeze(0))\n",
    "    out, reconstruction = model(x)\n",
    "    prob = torch.sqrt((out ** 2).sum(-1)).squeeze(0)\n",
    "    _, y_pred = torch.max(prob, 0)\n",
    "    print('Predict: %s, Actual: %s' % (y_pred.data[0], y))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    actual = x.data.squeeze(0).squeeze(0).numpy() * 0.8031 + 0.1307\n",
    "    ax1.imshow(actual, cmap='gray')\n",
    "    rec = reconstruction.squeeze(0).data.numpy() * 0.8031 + 0.1307\n",
    "    ax2.imshow(rec, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 3, Actual: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOgBEgoIOAJGgoANAJP4fOTyUKOvWpMUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39dddc6c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(model, dset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ddf5edbbe4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, (x, y) in enumerate(iter(loader_test)):\n",
    "    x = Variable(x)\n",
    "    out, _ = model(x)\n",
    "    prob = torch.sqrt((out ** 2).sum(-1))\n",
    "    _, y_pred = torch.max(prob, 1)\n",
    "    correct += y_pred.data.eq(y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %s' % (correct / len(dset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
